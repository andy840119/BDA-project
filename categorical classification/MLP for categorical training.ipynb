{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_for_categorical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396607, 2)\n"
     ]
    }
   ],
   "source": [
    "Classification = [\"world\",\"politics\",\"sport\",\"football\",\"culture\",\"business\",\n",
    "                  \"lifeandstyle\", \"fashion\",\"environment\",\"technology\",\"travel\"]\n",
    "data = data.loc[data['class'].isin(Classification)]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ...,  9,  9,  9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.as_matrix(columns=['class']).reshape(-1)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "num_classes = len(list(le.classes_))\n",
    "Y = le.transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np_utils.to_categorical(Y, num_classes)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<396607x13135 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4157578 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=55, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(data['name'].tolist())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, activation='tanh', input_shape=(X.shape[1],), bias_initializer='RandomNormal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='RMSprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=6,\n",
    "                        batch_size=10000)\n",
    "    score = model.evaluate(X_test, y_test)[1]\n",
    "    print('\\n valid acc :%.4f'%(score))\n",
    "    pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    true = np.argmax(y_test, axis=1)\n",
    "    print(classification_report(true, pred, target_names=list(le.classes_)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8)\n",
    "# X_train= X_train.toarray()\n",
    "# X_test = X_test.toarray()\n",
    "X =X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 13)                170768    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                154       \n",
      "=================================================================\n",
      "Total params: 170,922\n",
      "Trainable params: 170,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "396607/396607 [==============================] - 12s - loss: 0.5590 - acc: 0.8304    \n",
      "Epoch 2/5\n",
      "396607/396607 [==============================] - 12s - loss: 0.5574 - acc: 0.8313    \n",
      "Epoch 3/5\n",
      "396607/396607 [==============================] - 12s - loss: 0.5585 - acc: 0.8311    \n",
      "Epoch 4/5\n",
      "396607/396607 [==============================] - 12s - loss: 0.5578 - acc: 0.8308    \n",
      "Epoch 5/5\n",
      "396607/396607 [==============================] - 12s - loss: 0.5561 - acc: 0.8312    \n"
     ]
    }
   ],
   "source": [
    "# history = model.fit(X_train, y_train, \n",
    "#                     epochs=5,\n",
    "#                     validation_data = (X_test, y_test),\n",
    "#                     batch_size=8000)\n",
    "# pred = np.argmax(model.predict(X_test), axis=1)\n",
    "# true = np.argmax(y_test, axis=1)\n",
    "# print(classification_report(true, pred, target_names=list(le.classes_)))\n",
    "# 0.5092\n",
    "#0.5889\n",
    "history = model.fit(X, Y, \n",
    "                    epochs=5,\n",
    "                    batch_size=8000)\n",
    "# pred = np.argmax(model.predict(X_test), axis=1)\n",
    "# true = np.argmax(y_test, axis=1)\n",
    "# print(classification_report(true, pred, target_names=list(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True)\n",
    "# acc = []\n",
    "# X = X.toarray()\n",
    "# for train_idx, test_idx in kf.split(X):\n",
    "#     print (\"Running Fold\")\n",
    "#     model = create_model()\n",
    "#     acc.append(train_and_evaluate_model(model, X[train_idx], Y[train_idx], X[test_idx], Y[test_idx]))\n",
    "#     del model\n",
    "# print('mean acc:%.4f'%(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('news_title_cls85.h5')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
