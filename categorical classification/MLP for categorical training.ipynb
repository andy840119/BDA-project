{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Merge, Input, Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for chunk in pd.read_csv('data_for_categorical.csv', chunksize=20000):\n",
    "    data.append(chunk)\n",
    "data = pd.concat(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIA exposed by frontline role along Afghanista...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iraq threatens action after Blackwater case co...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Racial or religious groups could be picked out...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US general  British hostage held in Iran</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan suicide bomber kills dozens at volley...</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  class\n",
       "0  CIA exposed by frontline role along Afghanista...  world\n",
       "1  Iraq threatens action after Blackwater case co...  world\n",
       "2  Racial or religious groups could be picked out...  world\n",
       "3           US general  British hostage held in Iran  world\n",
       "4  Pakistan suicide bomber kills dozens at volley...  world"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396607, 2)\n"
     ]
    }
   ],
   "source": [
    "Classification = [\"world\",\"politics\",\"sport\",\"football\",\"culture\",\"business\",\n",
    "                  \"lifeandstyle\", \"fashion\",\"environment\",\"technology\",\"travel\"]\n",
    "data = data.loc[data['class'].isin(Classification)]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ...,  9,  9,  9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data.as_matrix(columns=['class']).reshape(-1)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "num_classes = len(list(le.classes_))\n",
    "Y = le.transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np_utils.to_categorical(Y, num_classes)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.10709089854692429,\n",
       " 1: 0.019916441212585758,\n",
       " 2: 0.055447836271170205,\n",
       " 3: 0.014258447279044495,\n",
       " 4: 0.1847572029742289,\n",
       " 5: 0.093505661776015048,\n",
       " 6: 0.075989581626143762,\n",
       " 7: 0.19269705274995147,\n",
       " 8: 0.054696462745236471,\n",
       " 9: 0.020781277183710829,\n",
       " 10: 0.18085913763498879}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = {}\n",
    "weight = np.sum(Y, axis=0)\n",
    "total = Y.shape[0]\n",
    "for i in range(11):\n",
    "    class_weight[i] = weight[i]/total\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<396607x12097 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4098415 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=60, ngram_range=(1, 3))\n",
    "X = vectorizer.fit_transform(data['name'].tolist())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8)\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()\n",
    "#X =X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_branch():\n",
    "#     first_model = Sequential()\n",
    "#     first_model.add(Dense(12, activation='relu', input_shape=(X.shape[1],), bias_initializer='RandomNormal'))\n",
    "#     first_model.add(Dropout(0.5))\n",
    "#     first_model.add(Dense(100, activation='relu', input_shape=(X.shape[1],), bias_initializer='RandomNormal'))\n",
    "#     first_model.add(Dropout(0.5))\n",
    "#     first_model.add(Dense(100, activation='relu', input_shape=(X.shape[1],), bias_initializer='RandomNormal'))\n",
    "#     first_model.add(Dropout(0.5))\n",
    "#     return first_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu', input_shape=(X.shape[1],), bias_initializer='RandomNormal'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu', bias_initializer='RandomNormal'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='RMSprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                145176    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 11)                143       \n",
      "=================================================================\n",
      "Total params: 145,475\n",
      "Trainable params: 145,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 317285 samples, validate on 79322 samples\n",
      "Epoch 1/100\n",
      "317285/317285 [==============================] - 13s - loss: 0.3091 - acc: 0.2250 - val_loss: 2.2275 - val_acc: 0.2996\n",
      "Epoch 2/100\n",
      "317285/317285 [==============================] - 13s - loss: 0.2770 - acc: 0.3135 - val_loss: 2.0841 - val_acc: 0.3134\n",
      "Epoch 3/100\n",
      "317285/317285 [==============================] - 13s - loss: 0.2457 - acc: 0.3154 - val_loss: 1.9535 - val_acc: 0.3247\n",
      "Epoch 4/100\n",
      " 80000/317285 [======>.......................] - ETA: 8s - loss: 0.2278 - acc: 0.3307"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    class_weight = class_weight,\n",
    "                    batch_size=8000)\n",
    "\n",
    "# 0.5092\n",
    "#0.5889\n",
    "# history = model.fit([X,X], Y, \n",
    "#                     epochs=15,\n",
    "#                     batch_size=8000)\n",
    "# pred = np.argmax(model.predict(X_test), axis=1)\n",
    "# true = np.argmax(y_test, axis=1)\n",
    "# print(classification_report(true, pred, target_names=list(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(X_test ), axis=1)\n",
    "true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(true, pred, target_names=list(le.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=6,\n",
    "                        batch_size=10000)\n",
    "    score = model.evaluate(X_test, y_test)[1]\n",
    "    print('\\n valid acc :%.4f'%(score))\n",
    "    pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    true = np.argmax(y_test, axis=1)\n",
    "    print(classification_report(true, pred, target_names=list(le.classes_)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kf = KFold(n_splits=5, shuffle=True)\n",
    "# acc = []\n",
    "# X = X.toarray()\n",
    "# for train_idx, test_idx in kf.split(X):\n",
    "#     print (\"Running Fold\")\n",
    "#     model = create_model()\n",
    "#     acc.append(train_and_evaluate_model(model, X[train_idx], Y[train_idx], X[test_idx], Y[test_idx]))\n",
    "#     del model\n",
    "# print('mean acc:%.4f'%(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('news_title_cls85.h5')\n",
    "# joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
